{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "https://www.drivendata.org/competitions/57/nepal-earthquake/page/136/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>...</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "      <th>damage_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>802906</td>\n",
       "      <td>6</td>\n",
       "      <td>487</td>\n",
       "      <td>12198</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28830</td>\n",
       "      <td>8</td>\n",
       "      <td>900</td>\n",
       "      <td>2812</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94947</td>\n",
       "      <td>21</td>\n",
       "      <td>363</td>\n",
       "      <td>8973</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>590882</td>\n",
       "      <td>22</td>\n",
       "      <td>418</td>\n",
       "      <td>10694</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201944</td>\n",
       "      <td>11</td>\n",
       "      <td>131</td>\n",
       "      <td>1488</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id  geo_level_1_id  geo_level_2_id  geo_level_3_id  \\\n",
       "0       802906               6             487           12198   \n",
       "1        28830               8             900            2812   \n",
       "2        94947              21             363            8973   \n",
       "3       590882              22             418           10694   \n",
       "4       201944              11             131            1488   \n",
       "\n",
       "   count_floors_pre_eq  age  area_percentage  height_percentage  \\\n",
       "0                    2   30                6                  5   \n",
       "1                    2   10                8                  7   \n",
       "2                    2   10                5                  5   \n",
       "3                    2   10                6                  5   \n",
       "4                    3   30                8                  9   \n",
       "\n",
       "  land_surface_condition foundation_type  ... has_secondary_use_hotel  \\\n",
       "0                      t               r  ...                       0   \n",
       "1                      o               r  ...                       0   \n",
       "2                      t               r  ...                       0   \n",
       "3                      t               r  ...                       0   \n",
       "4                      t               r  ...                       0   \n",
       "\n",
       "  has_secondary_use_rental has_secondary_use_institution  \\\n",
       "0                        0                             0   \n",
       "1                        0                             0   \n",
       "2                        0                             0   \n",
       "3                        0                             0   \n",
       "4                        0                             0   \n",
       "\n",
       "  has_secondary_use_school has_secondary_use_industry  \\\n",
       "0                        0                          0   \n",
       "1                        0                          0   \n",
       "2                        0                          0   \n",
       "3                        0                          0   \n",
       "4                        0                          0   \n",
       "\n",
       "   has_secondary_use_health_post  has_secondary_use_gov_office  \\\n",
       "0                              0                             0   \n",
       "1                              0                             0   \n",
       "2                              0                             0   \n",
       "3                              0                             0   \n",
       "4                              0                             0   \n",
       "\n",
       "   has_secondary_use_use_police  has_secondary_use_other  damage_grade  \n",
       "0                             0                        0             3  \n",
       "1                             0                        0             2  \n",
       "2                             0                        0             3  \n",
       "3                             0                        0             2  \n",
       "4                             0                        0             3  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train = pd.read_csv('Data/train_values.csv')\n",
    "raw_label = pd.read_csv('Data/train_labels.csv')\n",
    "df = pd.merge(raw_train, raw_label, how=\"left\", on=\"building_id\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['age'] < 300) &\n",
    "        (df['height_percentage'] < df['height_percentage'].quantile(0.9)) &\n",
    "        (df['count_floors_pre_eq'] < df['count_floors_pre_eq'].quantile(0.9)) &\n",
    "        (df['area_percentage'] < df['area_percentage'].quantile(0.9))\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "building_id                               0\n",
       "geo_level_1_id                            0\n",
       "geo_level_2_id                            0\n",
       "geo_level_3_id                            0\n",
       "count_floors_pre_eq                       0\n",
       "age                                       0\n",
       "area_percentage                           0\n",
       "height_percentage                         0\n",
       "land_surface_condition                    0\n",
       "foundation_type                           0\n",
       "roof_type                                 0\n",
       "ground_floor_type                         0\n",
       "other_floor_type                          0\n",
       "position                                  0\n",
       "plan_configuration                        0\n",
       "has_superstructure_adobe_mud              0\n",
       "has_superstructure_mud_mortar_stone       0\n",
       "has_superstructure_stone_flag             0\n",
       "has_superstructure_cement_mortar_stone    0\n",
       "has_superstructure_mud_mortar_brick       0\n",
       "has_superstructure_cement_mortar_brick    0\n",
       "has_superstructure_timber                 0\n",
       "has_superstructure_bamboo                 0\n",
       "has_superstructure_rc_non_engineered      0\n",
       "has_superstructure_rc_engineered          0\n",
       "has_superstructure_other                  0\n",
       "legal_ownership_status                    0\n",
       "count_families                            0\n",
       "has_secondary_use                         0\n",
       "has_secondary_use_agriculture             0\n",
       "has_secondary_use_hotel                   0\n",
       "has_secondary_use_rental                  0\n",
       "has_secondary_use_institution             0\n",
       "has_secondary_use_school                  0\n",
       "has_secondary_use_industry                0\n",
       "has_secondary_use_health_post             0\n",
       "has_secondary_use_gov_office              0\n",
       "has_secondary_use_use_police              0\n",
       "has_secondary_use_other                   0\n",
       "damage_grade                              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for NA values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables for ColumnTransformer\n",
    "numerical = ['count_floors_pre_eq', 'age', 'area_percentage', 'height_percentage', 'count_families']\n",
    "\n",
    "categorical = ['land_surface_condition', 'foundation_type', 'roof_type', 'ground_floor_type', 'other_floor_type', 'position', 'plan_configuration', 'legal_ownership_status']\n",
    "\n",
    "binary = ['has_superstructure_adobe_mud', 'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag', 'has_superstructure_cement_mortar_stone', 'has_superstructure_mud_mortar_brick', 'has_superstructure_cement_mortar_brick', 'has_superstructure_timber', 'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered', 'has_superstructure_rc_engineered', 'has_superstructure_other', 'has_secondary_use', 'has_secondary_use_agriculture', 'has_secondary_use_hotel', 'has_secondary_use_rental', 'has_secondary_use_institution', 'has_secondary_use_school', 'has_secondary_use_industry', 'has_secondary_use_health_post', 'has_secondary_use_gov_office', 'has_secondary_use_use_police', 'has_secondary_use_other', 'geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]\n",
    ")\n",
    "\n",
    "binary_transformer = Pipeline(\n",
    "    steps=[(\"ordinal\", OneHotEncoder(handle_unknown=\"ignore\"))]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numerical),\n",
    "        (\"cat\", categorical_transformer, categorical),\n",
    "        (\"binary\", binary_transformer, binary)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting and Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[numerical + categorical + binary]\n",
    "label = df['damage_grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, label, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = preprocessor.fit(X_train)\n",
    "train_x, test_x = pipeline.transform(X_train), pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7400760892972508\n",
      "[[ 1258  1404    69]\n",
      " [  601 13881  1754]\n",
      " [   82  3332  5481]]\n",
      "\n",
      "\n",
      "0.7380661833321369\n",
      "[[ 1276  1331    72]\n",
      " [  646 13814  1788]\n",
      " [   75  3386  5474]]\n",
      "\n",
      "\n",
      "0.7408298040341684\n",
      "[[ 1287  1384    72]\n",
      " [  606 13870  1853]\n",
      " [   79  3227  5484]]\n",
      "\n",
      "\n",
      "0.7410358565737052\n",
      "[[ 1254  1347    76]\n",
      " [  639 14060  1724]\n",
      " [   78  3351  5332]]\n",
      "\n",
      "\n",
      "0.7442661785291267\n",
      "[[ 1312  1410    54]\n",
      " [  577 13943  1723]\n",
      " [  105  3256  5481]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for train_index, test_index in kf.split(train_x):\n",
    "    X_train_cv, X_test_cv = train_x[train_index], train_x[test_index]\n",
    "    y_train_cv, y_test_cv = y_train.to_numpy()[train_index], y_train.to_numpy()[test_index]\n",
    "\n",
    "    clf = LogisticRegression(solver=\"lbfgs\", max_iter=100000,\n",
    "                             multi_class = \"multinomial\")\n",
    "    clf.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "    predict = clf.predict(X_test_cv)\n",
    "    print(accuracy_score(y_test_cv, predict))\n",
    "    print(confusion_matrix(y_test_cv, predict))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized CV Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 0.5, 1, 5, 10],\n",
    "    'solver': ['newton-cg', 'sag', 'saga', 'lbfgs']\n",
    "}\n",
    "\n",
    "# model\n",
    "logistic = LogisticRegression(multi_class = \"multinomial\", max_iter=100000,\n",
    "                             penalty=\"l2\")\n",
    "\n",
    "# cross validation\n",
    "cv = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7423981463544409\n",
      "Best Hyperparameters: {'solver': 'sag', 'C': 0.5}\n"
     ]
    }
   ],
   "source": [
    "search = RandomizedSearchCV(estimator=logistic, param_distributions=param_grid, n_iter=10, scoring=\"accuracy\", n_jobs=-1, cv=cv)\n",
    "search.fit(train_x, y_train)\n",
    "print('Best Score: %s' % search.best_score_)\n",
    "print('Best Hyperparameters: %s' % search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7445372842909237\n"
     ]
    }
   ],
   "source": [
    "svc_prediction = search.predict(test_x)\n",
    "print(f\"Accuracy score: {accuracy_score(y_test, svc_prediction)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0070629f0490a06d53c1eea2cd4f8ac166eb28e49f5af4686f76a098962da409"
  },
  "kernelspec": {
   "display_name": "jupyter_310",
   "language": "python",
   "name": "jupyter_310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
