{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "https://www.drivendata.org/competitions/57/nepal-earthquake/page/136/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   building_id  geo_level_1_id  geo_level_2_id  geo_level_3_id  \\\n0       802906               6             487           12198   \n1        28830               8             900            2812   \n2        94947              21             363            8973   \n3       590882              22             418           10694   \n4       201944              11             131            1488   \n\n   count_floors_pre_eq  age  area_percentage  height_percentage  \\\n0                    2   30                6                  5   \n1                    2   10                8                  7   \n2                    2   10                5                  5   \n3                    2   10                6                  5   \n4                    3   30                8                  9   \n\n  land_surface_condition foundation_type  ... has_secondary_use_hotel  \\\n0                      t               r  ...                       0   \n1                      o               r  ...                       0   \n2                      t               r  ...                       0   \n3                      t               r  ...                       0   \n4                      t               r  ...                       0   \n\n  has_secondary_use_rental has_secondary_use_institution  \\\n0                        0                             0   \n1                        0                             0   \n2                        0                             0   \n3                        0                             0   \n4                        0                             0   \n\n  has_secondary_use_school has_secondary_use_industry  \\\n0                        0                          0   \n1                        0                          0   \n2                        0                          0   \n3                        0                          0   \n4                        0                          0   \n\n   has_secondary_use_health_post  has_secondary_use_gov_office  \\\n0                              0                             0   \n1                              0                             0   \n2                              0                             0   \n3                              0                             0   \n4                              0                             0   \n\n   has_secondary_use_use_police  has_secondary_use_other  damage_grade  \n0                             0                        0             3  \n1                             0                        0             2  \n2                             0                        0             3  \n3                             0                        0             2  \n4                             0                        0             3  \n\n[5 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>building_id</th>\n      <th>geo_level_1_id</th>\n      <th>geo_level_2_id</th>\n      <th>geo_level_3_id</th>\n      <th>count_floors_pre_eq</th>\n      <th>age</th>\n      <th>area_percentage</th>\n      <th>height_percentage</th>\n      <th>land_surface_condition</th>\n      <th>foundation_type</th>\n      <th>...</th>\n      <th>has_secondary_use_hotel</th>\n      <th>has_secondary_use_rental</th>\n      <th>has_secondary_use_institution</th>\n      <th>has_secondary_use_school</th>\n      <th>has_secondary_use_industry</th>\n      <th>has_secondary_use_health_post</th>\n      <th>has_secondary_use_gov_office</th>\n      <th>has_secondary_use_use_police</th>\n      <th>has_secondary_use_other</th>\n      <th>damage_grade</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>802906</td>\n      <td>6</td>\n      <td>487</td>\n      <td>12198</td>\n      <td>2</td>\n      <td>30</td>\n      <td>6</td>\n      <td>5</td>\n      <td>t</td>\n      <td>r</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28830</td>\n      <td>8</td>\n      <td>900</td>\n      <td>2812</td>\n      <td>2</td>\n      <td>10</td>\n      <td>8</td>\n      <td>7</td>\n      <td>o</td>\n      <td>r</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>94947</td>\n      <td>21</td>\n      <td>363</td>\n      <td>8973</td>\n      <td>2</td>\n      <td>10</td>\n      <td>5</td>\n      <td>5</td>\n      <td>t</td>\n      <td>r</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>590882</td>\n      <td>22</td>\n      <td>418</td>\n      <td>10694</td>\n      <td>2</td>\n      <td>10</td>\n      <td>6</td>\n      <td>5</td>\n      <td>t</td>\n      <td>r</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>201944</td>\n      <td>11</td>\n      <td>131</td>\n      <td>1488</td>\n      <td>3</td>\n      <td>30</td>\n      <td>8</td>\n      <td>9</td>\n      <td>t</td>\n      <td>r</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 40 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train = pd.read_csv('Data/train_values.csv')\n",
    "raw_label = pd.read_csv('Data/train_labels.csv')\n",
    "df = pd.merge(raw_train, raw_label, how=\"left\", on=\"building_id\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers\n",
    "df = df[(df['age'] < 300) &\n",
    "        (df['height_percentage'] < df['height_percentage'].quantile(0.9)) &\n",
    "        (df['count_floors_pre_eq'] < df['count_floors_pre_eq'].quantile(0.9)) &\n",
    "        (df['area_percentage'] < df['area_percentage'].quantile(0.9))\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "building_id                               0\ngeo_level_1_id                            0\ngeo_level_2_id                            0\ngeo_level_3_id                            0\ncount_floors_pre_eq                       0\nage                                       0\narea_percentage                           0\nheight_percentage                         0\nland_surface_condition                    0\nfoundation_type                           0\nroof_type                                 0\nground_floor_type                         0\nother_floor_type                          0\nposition                                  0\nplan_configuration                        0\nhas_superstructure_adobe_mud              0\nhas_superstructure_mud_mortar_stone       0\nhas_superstructure_stone_flag             0\nhas_superstructure_cement_mortar_stone    0\nhas_superstructure_mud_mortar_brick       0\nhas_superstructure_cement_mortar_brick    0\nhas_superstructure_timber                 0\nhas_superstructure_bamboo                 0\nhas_superstructure_rc_non_engineered      0\nhas_superstructure_rc_engineered          0\nhas_superstructure_other                  0\nlegal_ownership_status                    0\ncount_families                            0\nhas_secondary_use                         0\nhas_secondary_use_agriculture             0\nhas_secondary_use_hotel                   0\nhas_secondary_use_rental                  0\nhas_secondary_use_institution             0\nhas_secondary_use_school                  0\nhas_secondary_use_industry                0\nhas_secondary_use_health_post             0\nhas_secondary_use_gov_office              0\nhas_secondary_use_use_police              0\nhas_secondary_use_other                   0\ndamage_grade                              0\ndtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for NA values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define variables for ColumnTransformer\n",
    "# numerical = ['count_floors_pre_eq', 'age', 'area_percentage', 'height_percentage', 'count_families']\n",
    "\n",
    "# categorical = ['land_surface_condition', 'foundation_type', 'roof_type', 'ground_floor_type', 'other_floor_type', 'position', 'plan_configuration', 'legal_ownership_status']\n",
    "\n",
    "# binary = ['has_superstructure_adobe_mud', 'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag', 'has_superstructure_cement_mortar_stone', 'has_superstructure_mud_mortar_brick', 'has_superstructure_cement_mortar_brick', 'has_superstructure_timber', 'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered', 'has_superstructure_rc_engineered', 'has_superstructure_other', 'has_secondary_use', 'has_secondary_use_agriculture', 'has_secondary_use_hotel', 'has_secondary_use_rental', 'has_secondary_use_institution', 'has_secondary_use_school', 'has_secondary_use_industry', 'has_secondary_use_health_post', 'has_secondary_use_gov_office', 'has_secondary_use_use_police', 'has_secondary_use_other', 'geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['count_families', 'count_floors_pre_eq', 'height_percentage', 'area_percentage', 'age']\n",
    "\n",
    "categorical = ['other_floor_type', 'ground_floor_type', 'roof_type', 'foundation_type']\n",
    "\n",
    "binary = ['has_superstructure_timber', 'has_superstructure_cement_mortar_brick', 'has_superstructure_mud_mortar_stone', 'geo_level_3_id', 'geo_level_2_id', 'geo_level_1_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]\n",
    ")\n",
    "\n",
    "binary_transformer = Pipeline(\n",
    "    steps=[(\"ordinal\", OneHotEncoder(handle_unknown=\"ignore\"))]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numerical),\n",
    "        (\"cat\", categorical_transformer, categorical),\n",
    "        (\"binary\", binary_transformer, binary)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train = df[numerical + categorical + binary]\n",
    "label = df['damage_grade']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, label, test_size=0.2, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "pipeline = preprocessor.fit(X_train)\n",
    "train_x, test_x = pipeline.transform(X_train), pipeline.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting and Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7359486038331778\n",
      "[[ 1286  1457    63]\n",
      " [  617 13815  1734]\n",
      " [   91  3395  5404]]\n",
      "\n",
      "\n",
      "0.7388557892470031\n",
      "[[ 1239  1352    61]\n",
      " [  596 14008  1794]\n",
      " [   89  3384  5339]]\n",
      "\n",
      "\n",
      "0.7384250951116216\n",
      "[[ 1347  1337    69]\n",
      " [  620 13765  1879]\n",
      " [   76  3307  5462]]\n",
      "\n",
      "\n",
      "0.7405333620473062\n",
      "[[ 1273  1354    55]\n",
      " [  625 13936  1808]\n",
      " [   79  3308  5423]]\n",
      "\n",
      "\n",
      "0.740605146979649\n",
      "[[ 1261  1413    69]\n",
      " [  634 13986  1705]\n",
      " [   64  3342  5387]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for train_index, test_index in kf.split(train_x):\n",
    "    X_train_cv, X_test_cv = train_x[train_index], train_x[test_index]\n",
    "    y_train_cv, y_test_cv = y_train.to_numpy()[train_index], y_train.to_numpy()[test_index]\n",
    "\n",
    "    clf = LogisticRegression(solver=\"lbfgs\", max_iter=100000,\n",
    "                             multi_class = \"multinomial\")\n",
    "    clf.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "    predict = clf.predict(X_test_cv)\n",
    "    print(accuracy_score(y_test_cv, predict))\n",
    "    print(confusion_matrix(y_test_cv, predict))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized CV Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $l_2$ Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 0.5, 1, 5, 10],\n",
    "    'solver': ['newton-cg', 'sag', 'saga', 'lbfgs']\n",
    "}\n",
    "\n",
    "# model\n",
    "logistic = LogisticRegression(multi_class = \"multinomial\", max_iter=100000,\n",
    "                             penalty=\"l2\")\n",
    "\n",
    "# cross validation\n",
    "# cv = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7402087718750006\n",
      "Best Hyperparameters: {'solver': 'saga', 'C': 0.5}\n"
     ]
    }
   ],
   "source": [
    "search = RandomizedSearchCV(estimator=logistic, param_distributions=param_grid, n_iter=10, scoring=\"accuracy\", n_jobs=-1)\n",
    "search.fit(train_x, y_train)\n",
    "print('Best Score: %s' % search.best_score_)\n",
    "print('Best Hyperparameters: %s' % search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.74137881528699\n"
     ]
    }
   ],
   "source": [
    "svc_prediction = search.predict(test_x)\n",
    "print(f\"Accuracy score: {accuracy_score(y_test, svc_prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $l_1$ Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_l1 = {\n",
    "    'C': [0.01, 0.1, 0.5, 1, 5, 10],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "logistic_l1 = LogisticRegression(multi_class = \"multinomial\", max_iter=100000,\n",
    "                                 penalty=\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/gr/rg2xxzy913dfhz2bd0vyj6d80000gn/T/ipykernel_39295/924360747.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0msearch_l1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mRandomizedSearchCV\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlogistic_l1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparam_distributions\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mparam_grid_l1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_iter\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscoring\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"accuracy\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0msearch_l1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_x\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Best Score: %s'\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0msearch_l1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbest_score_\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Best Hyperparameters: %s'\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0msearch_l1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbest_params_\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/virtualenvs/jupyter_data_spell_310/lib/python3.10/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    889\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mresults\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    890\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 891\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_run_search\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mevaluate_candidates\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    892\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    893\u001B[0m             \u001B[0;31m# multimetric is determined here because in the case of a callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/virtualenvs/jupyter_data_spell_310/lib/python3.10/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36m_run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1764\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_run_search\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevaluate_candidates\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1765\u001B[0m         \u001B[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1766\u001B[0;31m         evaluate_candidates(\n\u001B[0m\u001B[1;32m   1767\u001B[0m             ParameterSampler(\n\u001B[1;32m   1768\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparam_distributions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mn_iter\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandom_state\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/virtualenvs/jupyter_data_spell_310/lib/python3.10/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36mevaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    836\u001B[0m                     )\n\u001B[1;32m    837\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 838\u001B[0;31m                 out = parallel(\n\u001B[0m\u001B[1;32m    839\u001B[0m                     delayed(_fit_and_score)(\n\u001B[1;32m    840\u001B[0m                         \u001B[0mclone\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase_estimator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/virtualenvs/jupyter_data_spell_310/lib/python3.10/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1054\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1055\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mretrieval_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1056\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mretrieve\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1057\u001B[0m             \u001B[0;31m# Make sure that we get a last message telling us we are done\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1058\u001B[0m             \u001B[0melapsed_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_start_time\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/virtualenvs/jupyter_data_spell_310/lib/python3.10/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36mretrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    933\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    934\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'supports_timeout'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 935\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    936\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    937\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/virtualenvs/jupyter_data_spell_310/lib/python3.10/site-packages/joblib/_parallel_backends.py\u001B[0m in \u001B[0;36mwrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    540\u001B[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001B[1;32m    541\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 542\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfuture\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    543\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mCfTimeoutError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    544\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mTimeoutError\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py\u001B[0m in \u001B[0;36mresult\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    438\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__get_result\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    439\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 440\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_condition\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    441\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    442\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_state\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mCANCELLED\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mCANCELLED_AND_NOTIFIED\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py\u001B[0m in \u001B[0;36mwait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    318\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m    \u001B[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    319\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 320\u001B[0;31m                 \u001B[0mwaiter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0macquire\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    321\u001B[0m                 \u001B[0mgotit\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    322\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "search_l1 = RandomizedSearchCV(estimator=logistic_l1, param_distributions=param_grid_l1, n_iter=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "search_l1.fit(train_x, y_train)\n",
    "print('Best Score: %s' % search_l1.best_score_)\n",
    "print('Best Hyperparameters: %s' % search_l1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_prediction_l1 = search_l1.predict(test_x)\n",
    "print(f\"Accuracy score: {accuracy_score(y_test, svc_prediction_l1)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0070629f0490a06d53c1eea2cd4f8ac166eb28e49f5af4686f76a098962da409"
  },
  "kernelspec": {
   "name": "jupyter-dataspell-310",
   "language": "python",
   "display_name": "jupyter-dataspell-310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}